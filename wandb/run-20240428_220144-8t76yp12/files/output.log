CUDA set: True
Files already downloaded and verified
Files already downloaded and verified
/home/linwei/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Train Epoch: 0 [0/45056 (0%)]	Loss: 302.263794
/home/linwei/calibration-feature/train_utils.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 2)
Train Epoch: 0 [1280/45056 (3%)]	Loss: 306.680725
Train Epoch: 0 [2560/45056 (6%)]	Loss: 443.342102
Train Epoch: 0 [3840/45056 (9%)]	Loss: 353.270294
Train Epoch: 0 [5120/45056 (11%)]	Loss: 380.565186
Train Epoch: 0 [6400/45056 (14%)]	Loss: 330.513611
Train Epoch: 0 [7680/45056 (17%)]	Loss: 345.227539
Train Epoch: 0 [8960/45056 (20%)]	Loss: 330.234161
Train Epoch: 0 [10240/45056 (23%)]	Loss: 279.345520
Train Epoch: 0 [11520/45056 (26%)]	Loss: 297.430695
Train Epoch: 0 [12800/45056 (28%)]	Loss: 247.779724
Train Epoch: 0 [14080/45056 (31%)]	Loss: 267.949432
Train Epoch: 0 [15360/45056 (34%)]	Loss: 255.469101
Train Epoch: 0 [16640/45056 (37%)]	Loss: 254.317322
Train Epoch: 0 [17920/45056 (40%)]	Loss: 255.662857
Train Epoch: 0 [19200/45056 (43%)]	Loss: 244.841629
Train Epoch: 0 [20480/45056 (45%)]	Loss: 250.976685
Train Epoch: 0 [21760/45056 (48%)]	Loss: 240.673706
Train Epoch: 0 [23040/45056 (51%)]	Loss: 248.745743
Train Epoch: 0 [24320/45056 (54%)]	Loss: 244.426010
Train Epoch: 0 [25600/45056 (57%)]	Loss: 236.116302
Train Epoch: 0 [26880/45056 (60%)]	Loss: 228.118927
Train Epoch: 0 [28160/45056 (62%)]	Loss: 232.604660
Train Epoch: 0 [29440/45056 (65%)]	Loss: 261.665314
Train Epoch: 0 [30720/45056 (68%)]	Loss: 190.546295
Train Epoch: 0 [32000/45056 (71%)]	Loss: 234.688873
Train Epoch: 0 [33280/45056 (74%)]	Loss: 243.793930
Train Epoch: 0 [34560/45056 (77%)]	Loss: 213.411301
Train Epoch: 0 [35840/45056 (80%)]	Loss: 200.682266
Train Epoch: 0 [37120/45056 (82%)]	Loss: 217.895859
Train Epoch: 0 [38400/45056 (85%)]	Loss: 211.463409
Train Epoch: 0 [39680/45056 (88%)]	Loss: 198.138824
Train Epoch: 0 [40960/45056 (91%)]	Loss: 185.014252
Train Epoch: 0 [42240/45056 (94%)]	Loss: 223.547913
Train Epoch: 0 [43520/45056 (97%)]	Loss: 228.640778
Train Epoch: 0 [44800/45056 (99%)]	Loss: 193.002136
====> Epoch: 0 Average loss: 2.0027
/home/linwei/calibration-feature/train_utils.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 2)
Epoch: 1/200  Origin test Acc: 0.2431  Origin Pre test ECE: 0.2667965292930603
Train Epoch: 1 [0/45056 (0%)]	Loss: 222.376480
Train Epoch: 1 [1280/45056 (3%)]	Loss: 196.271942
Train Epoch: 1 [2560/45056 (6%)]	Loss: 186.253632
Train Epoch: 1 [3840/45056 (9%)]	Loss: 200.527863
Train Epoch: 1 [5120/45056 (11%)]	Loss: 195.027664
Train Epoch: 1 [6400/45056 (14%)]	Loss: 197.199783
Train Epoch: 1 [7680/45056 (17%)]	Loss: 186.776062
Train Epoch: 1 [8960/45056 (20%)]	Loss: 171.608398
Train Epoch: 1 [10240/45056 (23%)]	Loss: 180.083023
Train Epoch: 1 [11520/45056 (26%)]	Loss: 201.046341
Train Epoch: 1 [12800/45056 (28%)]	Loss: 175.377319
Train Epoch: 1 [14080/45056 (31%)]	Loss: 182.887573
Train Epoch: 1 [15360/45056 (34%)]	Loss: 203.087265
Train Epoch: 1 [16640/45056 (37%)]	Loss: 184.656799
Train Epoch: 1 [17920/45056 (40%)]	Loss: 163.445663
Train Epoch: 1 [19200/45056 (43%)]	Loss: 178.193542
Train Epoch: 1 [20480/45056 (45%)]	Loss: 189.697708
Train Epoch: 1 [21760/45056 (48%)]	Loss: 199.006866
Train Epoch: 1 [23040/45056 (51%)]	Loss: 162.357010
Train Epoch: 1 [24320/45056 (54%)]	Loss: 167.744232
Train Epoch: 1 [25600/45056 (57%)]	Loss: 193.473434
Train Epoch: 1 [26880/45056 (60%)]	Loss: 172.267059
Train Epoch: 1 [28160/45056 (62%)]	Loss: 166.654434
Train Epoch: 1 [29440/45056 (65%)]	Loss: 157.355896
Train Epoch: 1 [30720/45056 (68%)]	Loss: 176.250458
Train Epoch: 1 [32000/45056 (71%)]	Loss: 172.371857
Train Epoch: 1 [33280/45056 (74%)]	Loss: 143.717743
Train Epoch: 1 [34560/45056 (77%)]	Loss: 144.808884
Train Epoch: 1 [35840/45056 (80%)]	Loss: 160.745117
Train Epoch: 1 [37120/45056 (82%)]	Loss: 163.545868
Train Epoch: 1 [38400/45056 (85%)]	Loss: 170.309219
Train Epoch: 1 [39680/45056 (88%)]	Loss: 188.068863
Train Epoch: 1 [40960/45056 (91%)]	Loss: 165.906067
Train Epoch: 1 [42240/45056 (94%)]	Loss: 151.150070
Train Epoch: 1 [43520/45056 (97%)]	Loss: 148.671539
Train Epoch: 1 [44800/45056 (99%)]	Loss: 154.794937
====> Epoch: 1 Average loss: 1.3561
/home/linwei/calibration-feature/train_utils.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 2)
Epoch: 2/200  Origin test Acc: 0.575  Origin Pre test ECE: 0.03959100693464279
Train Epoch: 2 [0/45056 (0%)]	Loss: 158.705109
Train Epoch: 2 [1280/45056 (3%)]	Loss: 175.389557
Train Epoch: 2 [2560/45056 (6%)]	Loss: 154.611710
Train Epoch: 2 [3840/45056 (9%)]	Loss: 155.094940
Train Epoch: 2 [5120/45056 (11%)]	Loss: 171.479706
Train Epoch: 2 [6400/45056 (14%)]	Loss: 160.889771
Train Epoch: 2 [7680/45056 (17%)]	Loss: 160.112549
Train Epoch: 2 [8960/45056 (20%)]	Loss: 150.403641
Train Epoch: 2 [10240/45056 (23%)]	Loss: 119.336243
Train Epoch: 2 [11520/45056 (26%)]	Loss: 161.156540
Train Epoch: 2 [12800/45056 (28%)]	Loss: 131.535553
Train Epoch: 2 [14080/45056 (31%)]	Loss: 138.597015
Train Epoch: 2 [15360/45056 (34%)]	Loss: 134.720459
Train Epoch: 2 [16640/45056 (37%)]	Loss: 161.615158
Train Epoch: 2 [17920/45056 (40%)]	Loss: 143.751663
Train Epoch: 2 [19200/45056 (43%)]	Loss: 151.126328
Train Epoch: 2 [20480/45056 (45%)]	Loss: 150.244705
Train Epoch: 2 [21760/45056 (48%)]	Loss: 153.337692
Train Epoch: 2 [23040/45056 (51%)]	Loss: 160.360596
Train Epoch: 2 [24320/45056 (54%)]	Loss: 122.969017
Train Epoch: 2 [25600/45056 (57%)]	Loss: 129.279678
Train Epoch: 2 [26880/45056 (60%)]	Loss: 133.843979
Train Epoch: 2 [28160/45056 (62%)]	Loss: 154.323227
Train Epoch: 2 [29440/45056 (65%)]	Loss: 128.656174
Train Epoch: 2 [30720/45056 (68%)]	Loss: 125.252159
Train Epoch: 2 [32000/45056 (71%)]	Loss: 148.119980
Train Epoch: 2 [33280/45056 (74%)]	Loss: 127.980339
Train Epoch: 2 [34560/45056 (77%)]	Loss: 145.882675
Train Epoch: 2 [35840/45056 (80%)]	Loss: 132.887482
Train Epoch: 2 [37120/45056 (82%)]	Loss: 146.670273
Train Epoch: 2 [38400/45056 (85%)]	Loss: 145.616470
Train Epoch: 2 [39680/45056 (88%)]	Loss: 133.543503
Train Epoch: 2 [40960/45056 (91%)]	Loss: 142.099640
Train Epoch: 2 [42240/45056 (94%)]	Loss: 138.558777
Train Epoch: 2 [43520/45056 (97%)]	Loss: 143.997253
Train Epoch: 2 [44800/45056 (99%)]	Loss: 138.596588
====> Epoch: 2 Average loss: 1.1124
Epoch: 3/200  Origin test Acc: 0.4859  Origin Pre test ECE: 0.16128474473953247
/home/linwei/calibration-feature/train_utils.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 2)
Train Epoch: 3 [0/45056 (0%)]	Loss: 120.092285
Train Epoch: 3 [1280/45056 (3%)]	Loss: 126.384071
Train Epoch: 3 [2560/45056 (6%)]	Loss: 118.029602
Train Epoch: 3 [3840/45056 (9%)]	Loss: 124.307144
Train Epoch: 3 [5120/45056 (11%)]	Loss: 147.525284
Train Epoch: 3 [6400/45056 (14%)]	Loss: 127.975708
Train Epoch: 3 [7680/45056 (17%)]	Loss: 127.993752
Train Epoch: 3 [8960/45056 (20%)]	Loss: 101.190117
Train Epoch: 3 [10240/45056 (23%)]	Loss: 141.535568
Train Epoch: 3 [11520/45056 (26%)]	Loss: 111.199509
Train Epoch: 3 [12800/45056 (28%)]	Loss: 133.561737
Train Epoch: 3 [14080/45056 (31%)]	Loss: 127.561409
Train Epoch: 3 [15360/45056 (34%)]	Loss: 142.317352
Train Epoch: 3 [16640/45056 (37%)]	Loss: 125.960503
Train Epoch: 3 [17920/45056 (40%)]	Loss: 131.203461
Train Epoch: 3 [19200/45056 (43%)]	Loss: 131.729416
Train Epoch: 3 [20480/45056 (45%)]	Loss: 125.386612
Train Epoch: 3 [21760/45056 (48%)]	Loss: 115.580963
Train Epoch: 3 [23040/45056 (51%)]	Loss: 116.584442
Train Epoch: 3 [24320/45056 (54%)]	Loss: 139.064743
Train Epoch: 3 [25600/45056 (57%)]	Loss: 121.802467
Train Epoch: 3 [26880/45056 (60%)]	Loss: 99.306671
Train Epoch: 3 [28160/45056 (62%)]	Loss: 139.804886
Train Epoch: 3 [29440/45056 (65%)]	Loss: 91.348244
Train Epoch: 3 [30720/45056 (68%)]	Loss: 114.010933
Train Epoch: 3 [32000/45056 (71%)]	Loss: 121.798615
Train Epoch: 3 [33280/45056 (74%)]	Loss: 117.090256
Train Epoch: 3 [34560/45056 (77%)]	Loss: 116.409851
Train Epoch: 3 [35840/45056 (80%)]	Loss: 104.319756
Train Epoch: 3 [37120/45056 (82%)]	Loss: 129.577148
Train Epoch: 3 [38400/45056 (85%)]	Loss: 116.314255
Train Epoch: 3 [39680/45056 (88%)]	Loss: 123.008026
Train Epoch: 3 [40960/45056 (91%)]	Loss: 113.916626
Train Epoch: 3 [42240/45056 (94%)]	Loss: 131.364883
Train Epoch: 3 [43520/45056 (97%)]	Loss: 107.982323
Train Epoch: 3 [44800/45056 (99%)]	Loss: 118.591789
====> Epoch: 3 Average loss: 0.9752
Epoch: 4/200  Origin test Acc: 0.6513  Origin Pre test ECE: 0.05524802580475807
Train Epoch: 4 [0/45056 (0%)]	Loss: 101.391838
/home/linwei/calibration-feature/train_utils.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 2)
Train Epoch: 4 [1280/45056 (3%)]	Loss: 131.812988
Train Epoch: 4 [2560/45056 (6%)]	Loss: 115.304268
Train Epoch: 4 [3840/45056 (9%)]	Loss: 125.344803
Train Epoch: 4 [5120/45056 (11%)]	Loss: 102.492203
Train Epoch: 4 [6400/45056 (14%)]	Loss: 123.108574
Train Epoch: 4 [7680/45056 (17%)]	Loss: 119.807198
Train Epoch: 4 [8960/45056 (20%)]	Loss: 100.874062
Train Epoch: 4 [10240/45056 (23%)]	Loss: 120.825432
Train Epoch: 4 [11520/45056 (26%)]	Loss: 113.299049
Train Epoch: 4 [12800/45056 (28%)]	Loss: 127.426590
Train Epoch: 4 [14080/45056 (31%)]	Loss: 103.697487
Train Epoch: 4 [15360/45056 (34%)]	Loss: 105.831673
Train Epoch: 4 [16640/45056 (37%)]	Loss: 133.251663
Train Epoch: 4 [17920/45056 (40%)]	Loss: 113.018623
Train Epoch: 4 [19200/45056 (43%)]	Loss: 121.828354
Train Epoch: 4 [20480/45056 (45%)]	Loss: 127.973175
Train Epoch: 4 [21760/45056 (48%)]	Loss: 117.195938
Train Epoch: 4 [23040/45056 (51%)]	Loss: 104.776222
Train Epoch: 4 [24320/45056 (54%)]	Loss: 116.656807
Train Epoch: 4 [25600/45056 (57%)]	Loss: 109.612015
Train Epoch: 4 [26880/45056 (60%)]	Loss: 140.289551
Train Epoch: 4 [28160/45056 (62%)]	Loss: 107.318062
Train Epoch: 4 [29440/45056 (65%)]	Loss: 97.594032
Train Epoch: 4 [30720/45056 (68%)]	Loss: 114.586960
Train Epoch: 4 [32000/45056 (71%)]	Loss: 113.236336
Train Epoch: 4 [33280/45056 (74%)]	Loss: 96.505623
Train Epoch: 4 [34560/45056 (77%)]	Loss: 100.759842
Train Epoch: 4 [35840/45056 (80%)]	Loss: 99.866577
Train Epoch: 4 [37120/45056 (82%)]	Loss: 103.655388
Train Epoch: 4 [38400/45056 (85%)]	Loss: 92.325493
Train Epoch: 4 [39680/45056 (88%)]	Loss: 99.360283
Train Epoch: 4 [40960/45056 (91%)]	Loss: 116.747749
Train Epoch: 4 [42240/45056 (94%)]	Loss: 103.363014
Train Epoch: 4 [43520/45056 (97%)]	Loss: 107.032867
Train Epoch: 4 [44800/45056 (99%)]	Loss: 116.512146
====> Epoch: 4 Average loss: 0.8711
Epoch: 5/200  Origin test Acc: 0.606  Origin Pre test ECE: 0.12929697334766388
Train Epoch: 5 [0/45056 (0%)]	Loss: 87.941299
/home/linwei/calibration-feature/train_utils.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 2)
Train Epoch: 5 [1280/45056 (3%)]	Loss: 99.534950
Train Epoch: 5 [2560/45056 (6%)]	Loss: 92.556358
Train Epoch: 5 [3840/45056 (9%)]	Loss: 109.821724
Train Epoch: 5 [5120/45056 (11%)]	Loss: 91.849663
Train Epoch: 5 [6400/45056 (14%)]	Loss: 114.410400
Train Epoch: 5 [7680/45056 (17%)]	Loss: 93.280624
Train Epoch: 5 [8960/45056 (20%)]	Loss: 108.721962
Train Epoch: 5 [10240/45056 (23%)]	Loss: 107.934776
Train Epoch: 5 [11520/45056 (26%)]	Loss: 103.216637
Train Epoch: 5 [12800/45056 (28%)]	Loss: 115.863091
Train Epoch: 5 [14080/45056 (31%)]	Loss: 94.641533
Train Epoch: 5 [15360/45056 (34%)]	Loss: 90.540787
Train Epoch: 5 [16640/45056 (37%)]	Loss: 89.437782
Train Epoch: 5 [17920/45056 (40%)]	Loss: 90.394218
Train Epoch: 5 [19200/45056 (43%)]	Loss: 106.365356
Train Epoch: 5 [20480/45056 (45%)]	Loss: 132.720932
Train Epoch: 5 [21760/45056 (48%)]	Loss: 90.794899
Train Epoch: 5 [23040/45056 (51%)]	Loss: 89.342216
Train Epoch: 5 [24320/45056 (54%)]	Loss: 114.492310
Train Epoch: 5 [25600/45056 (57%)]	Loss: 116.636131
Train Epoch: 5 [26880/45056 (60%)]	Loss: 93.542435
Train Epoch: 5 [28160/45056 (62%)]	Loss: 125.008438
Train Epoch: 5 [29440/45056 (65%)]	Loss: 86.078575
Train Epoch: 5 [30720/45056 (68%)]	Loss: 100.006119
Train Epoch: 5 [32000/45056 (71%)]	Loss: 106.509155
Train Epoch: 5 [33280/45056 (74%)]	Loss: 87.565666
Train Epoch: 5 [34560/45056 (77%)]	Loss: 90.359573
Train Epoch: 5 [35840/45056 (80%)]	Loss: 100.669769
Train Epoch: 5 [37120/45056 (82%)]	Loss: 97.490570
Train Epoch: 5 [38400/45056 (85%)]	Loss: 103.964607
Train Epoch: 5 [39680/45056 (88%)]	Loss: 77.242126
Train Epoch: 5 [40960/45056 (91%)]	Loss: 97.319893
Train Epoch: 5 [42240/45056 (94%)]	Loss: 87.116661
Train Epoch: 5 [43520/45056 (97%)]	Loss: 103.317535
Train Epoch: 5 [44800/45056 (99%)]	Loss: 120.024406
====> Epoch: 5 Average loss: 0.7965
Epoch: 6/200  Origin test Acc: 0.6741  Origin Pre test ECE: 0.08534826338291168
Train Epoch: 6 [0/45056 (0%)]	Loss: 99.917923
/home/linwei/calibration-feature/train_utils.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 2)
Train Epoch: 6 [1280/45056 (3%)]	Loss: 78.283974
Train Epoch: 6 [2560/45056 (6%)]	Loss: 90.409828
Train Epoch: 6 [3840/45056 (9%)]	Loss: 89.367157
Train Epoch: 6 [5120/45056 (11%)]	Loss: 92.587669
Train Epoch: 6 [6400/45056 (14%)]	Loss: 85.222351
Train Epoch: 6 [7680/45056 (17%)]	Loss: 95.131294
Train Epoch: 6 [8960/45056 (20%)]	Loss: 89.736511
Train Epoch: 6 [10240/45056 (23%)]	Loss: 117.445030
Train Epoch: 6 [11520/45056 (26%)]	Loss: 83.450539
Train Epoch: 6 [12800/45056 (28%)]	Loss: 65.617088
Train Epoch: 6 [14080/45056 (31%)]	Loss: 86.191391
Train Epoch: 6 [15360/45056 (34%)]	Loss: 103.697823
Train Epoch: 6 [16640/45056 (37%)]	Loss: 90.457565
Train Epoch: 6 [17920/45056 (40%)]	Loss: 77.192528
Train Epoch: 6 [19200/45056 (43%)]	Loss: 107.064629
Train Epoch: 6 [20480/45056 (45%)]	Loss: 91.982307
Train Epoch: 6 [21760/45056 (48%)]	Loss: 96.290977
Train Epoch: 6 [23040/45056 (51%)]	Loss: 77.186249
Train Epoch: 6 [24320/45056 (54%)]	Loss: 75.565598
Train Epoch: 6 [25600/45056 (57%)]	Loss: 85.740410
Train Epoch: 6 [26880/45056 (60%)]	Loss: 89.875900
Train Epoch: 6 [28160/45056 (62%)]	Loss: 97.623375
Train Epoch: 6 [29440/45056 (65%)]	Loss: 92.598679
Train Epoch: 6 [30720/45056 (68%)]	Loss: 78.154289
Train Epoch: 6 [32000/45056 (71%)]	Loss: 99.350563
Train Epoch: 6 [33280/45056 (74%)]	Loss: 85.630035
Train Epoch: 6 [34560/45056 (77%)]	Loss: 75.819931
Train Epoch: 6 [35840/45056 (80%)]	Loss: 119.573517
Train Epoch: 6 [37120/45056 (82%)]	Loss: 70.113579
Train Epoch: 6 [38400/45056 (85%)]	Loss: 78.636131
Train Epoch: 6 [39680/45056 (88%)]	Loss: 95.779533
Train Epoch: 6 [40960/45056 (91%)]	Loss: 71.699577
Train Epoch: 6 [42240/45056 (94%)]	Loss: 76.245239
Train Epoch: 6 [43520/45056 (97%)]	Loss: 99.606865
Train Epoch: 6 [44800/45056 (99%)]	Loss: 79.260635
====> Epoch: 6 Average loss: 0.7156
/home/linwei/calibration-feature/train_utils.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 2)
Epoch: 7/200  Origin test Acc: 0.7479  Origin Pre test ECE: 0.03919101506471634
Train Epoch: 7 [0/45056 (0%)]	Loss: 83.898331
Train Epoch: 7 [1280/45056 (3%)]	Loss: 90.733498
Train Epoch: 7 [2560/45056 (6%)]	Loss: 87.919716
Train Epoch: 7 [3840/45056 (9%)]	Loss: 76.011795
Train Epoch: 7 [5120/45056 (11%)]	Loss: 95.834724
Train Epoch: 7 [6400/45056 (14%)]	Loss: 97.653351
Train Epoch: 7 [7680/45056 (17%)]	Loss: 81.901802
Train Epoch: 7 [8960/45056 (20%)]	Loss: 88.389046
Train Epoch: 7 [10240/45056 (23%)]	Loss: 78.815865
Train Epoch: 7 [11520/45056 (26%)]	Loss: 81.167847
Train Epoch: 7 [12800/45056 (28%)]	Loss: 87.043602
Train Epoch: 7 [14080/45056 (31%)]	Loss: 84.187515
Train Epoch: 7 [15360/45056 (34%)]	Loss: 72.979179
Train Epoch: 7 [16640/45056 (37%)]	Loss: 85.313728
Train Epoch: 7 [17920/45056 (40%)]	Loss: 65.791702
Train Epoch: 7 [19200/45056 (43%)]	Loss: 95.087860
Train Epoch: 7 [20480/45056 (45%)]	Loss: 83.356911
Train Epoch: 7 [21760/45056 (48%)]	Loss: 78.720673
Train Epoch: 7 [23040/45056 (51%)]	Loss: 98.518951
Train Epoch: 7 [24320/45056 (54%)]	Loss: 90.032265
Train Epoch: 7 [25600/45056 (57%)]	Loss: 91.218712
Train Epoch: 7 [26880/45056 (60%)]	Loss: 105.014664
Train Epoch: 7 [28160/45056 (62%)]	Loss: 78.436134
Train Epoch: 7 [29440/45056 (65%)]	Loss: 99.855034
Train Epoch: 7 [30720/45056 (68%)]	Loss: 88.667038
Train Epoch: 7 [32000/45056 (71%)]	Loss: 86.078392
Train Epoch: 7 [33280/45056 (74%)]	Loss: 66.189178
Train Epoch: 7 [34560/45056 (77%)]	Loss: 70.870789
Train Epoch: 7 [35840/45056 (80%)]	Loss: 81.020348
Train Epoch: 7 [37120/45056 (82%)]	Loss: 76.450317
Train Epoch: 7 [38400/45056 (85%)]	Loss: 78.664558
Train Epoch: 7 [39680/45056 (88%)]	Loss: 84.099487
Train Epoch: 7 [40960/45056 (91%)]	Loss: 84.068359
Train Epoch: 7 [42240/45056 (94%)]	Loss: 71.034439
Train Epoch: 7 [43520/45056 (97%)]	Loss: 80.231728
Train Epoch: 7 [44800/45056 (99%)]	Loss: 65.390396
====> Epoch: 7 Average loss: 0.6533
/home/linwei/calibration-feature/train_utils.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 2)
Epoch: 8/200  Origin test Acc: 0.7245  Origin Pre test ECE: 0.06632469594478607
Train Epoch: 8 [0/45056 (0%)]	Loss: 87.848564
Train Epoch: 8 [1280/45056 (3%)]	Loss: 96.500282
Train Epoch: 8 [2560/45056 (6%)]	Loss: 51.319477
Train Epoch: 8 [3840/45056 (9%)]	Loss: 68.409912
Train Epoch: 8 [5120/45056 (11%)]	Loss: 99.565224
Train Epoch: 8 [6400/45056 (14%)]	Loss: 80.971390
Train Epoch: 8 [7680/45056 (17%)]	Loss: 85.834908
Train Epoch: 8 [8960/45056 (20%)]	Loss: 74.373962
Train Epoch: 8 [10240/45056 (23%)]	Loss: 80.581657
Train Epoch: 8 [11520/45056 (26%)]	Loss: 77.064590
Train Epoch: 8 [12800/45056 (28%)]	Loss: 89.860512
Train Epoch: 8 [14080/45056 (31%)]	Loss: 65.719536
Train Epoch: 8 [15360/45056 (34%)]	Loss: 75.130836
Train Epoch: 8 [16640/45056 (37%)]	Loss: 77.773476
Train Epoch: 8 [17920/45056 (40%)]	Loss: 65.070175
Train Epoch: 8 [19200/45056 (43%)]	Loss: 68.888481
Train Epoch: 8 [20480/45056 (45%)]	Loss: 76.217331
Train Epoch: 8 [21760/45056 (48%)]	Loss: 76.389374
Train Epoch: 8 [23040/45056 (51%)]	Loss: 92.845253
Train Epoch: 8 [24320/45056 (54%)]	Loss: 77.604256
Train Epoch: 8 [25600/45056 (57%)]	Loss: 96.083679
Train Epoch: 8 [26880/45056 (60%)]	Loss: 82.329086
Train Epoch: 8 [28160/45056 (62%)]	Loss: 71.421883
Train Epoch: 8 [29440/45056 (65%)]	Loss: 77.392769
Train Epoch: 8 [30720/45056 (68%)]	Loss: 74.679665
Train Epoch: 8 [32000/45056 (71%)]	Loss: 99.388680
Train Epoch: 8 [33280/45056 (74%)]	Loss: 88.620682
Train Epoch: 8 [34560/45056 (77%)]	Loss: 73.815933
Train Epoch: 8 [35840/45056 (80%)]	Loss: 82.708313
Train Epoch: 8 [37120/45056 (82%)]	Loss: 65.997467
Train Epoch: 8 [38400/45056 (85%)]	Loss: 74.347275
Train Epoch: 8 [39680/45056 (88%)]	Loss: 70.610001
Train Epoch: 8 [40960/45056 (91%)]	Loss: 62.092220
Train Epoch: 8 [42240/45056 (94%)]	Loss: 81.790878
Train Epoch: 8 [43520/45056 (97%)]	Loss: 86.295029
Train Epoch: 8 [44800/45056 (99%)]	Loss: 100.985863
====> Epoch: 8 Average loss: 0.6217
Traceback (most recent call last):
  File "/home/linwei/anaconda3/lib/python3.9/site-packages/torch/serialization.py", line 619, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)
  File "/home/linwei/anaconda3/lib/python3.9/site-packages/torch/serialization.py", line 853, in _save
    zip_file.write_record(name, storage.data_p